{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trafic Signs Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if tensorflow will use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish step 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "# K.tensorflow_backend._get_available_gpus()\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 48\n",
    "\n",
    "root_dir = 'GTSRB\\\\Final_Training\\\\Images\\\\'\n",
    "\n",
    "print(\"finish step 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number singns in training set: 39209\n",
      "Number of classes: 43\n"
     ]
    }
   ],
   "source": [
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "print(\"Number singns in training set: {}\".format(len(all_img_paths)))\n",
    "number_of_classes = glob.glob(os.path.join(root_dir, '*/00000_00000.ppm'))\n",
    "print(\"Number of classes: {}\".format(len(number_of_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sign from each class\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "imread() got an unexpected keyword argument 'as_gray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-193b3062dc0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Example sign from each class\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mimage_from_each_class_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*/00002_00010.ppm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mshowImagesInGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_from_each_class_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-193b3062dc0e>\u001b[0m in \u001b[0;36mshowImagesInGrid\u001b[1;34m(list_of_files)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_files\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         axis('off')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: imread() got an unexpected keyword argument 'as_gray'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure, imshow, axis, tight_layout, show\n",
    "from matplotlib.image import imread\n",
    "\n",
    "def showImagesInGrid(list_of_files):\n",
    "    fig = figure(figsize=(13, 13))\n",
    "    number_of_files = len(list_of_files)\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(number_of_files/7+1,8,i+1)\n",
    "        image = imread(list_of_files[i], as_gray=True)\n",
    "        imshow(image)\n",
    "#         axis('off')\n",
    "\n",
    "print(\"Example sign from each class\")\n",
    "image_from_each_class_paths = glob.glob(os.path.join(root_dir, '*/00002_00010.ppm'))\n",
    "showImagesInGrid(image_from_each_class_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample class trainig examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_from_class = 12\n",
    "\n",
    "examples_from_one_class_path = '*0{}/*_00029.ppm'.format(examples_from_class)\n",
    "print(\"Example signs from one class\")\n",
    "image_from_one_class_paths = glob.glob(os.path.join(root_dir, examples_from_one_class_path))\n",
    "showImagesInGrid(image_from_one_class_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sign real life sign in dataset has already generated 30 variation of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_from_class = 12\n",
    "sign_no_varations = 1\n",
    "\n",
    "examples_from_one_class_path = '*0{}/*0{}_*.ppm'.format(examples_from_class, sign_no_varations)\n",
    "print(\"Example signs from one class\")\n",
    "image_from_one_class_paths = glob.glob(os.path.join(root_dir, examples_from_one_class_path))\n",
    "showImagesInGrid(image_from_one_class_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "\n",
    "    img = preprocess_img_without_rollaxis(img)\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def preprocess_img_without_rollaxis(img):\n",
    "    # Histogram normalization in y\n",
    "#     hsv = color.rgb2hsv(img)\n",
    "#     hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "#     img = color.hsv2rgb(hsv)\n",
    "\n",
    "#     central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))    \n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('\\\\')[-2])\n",
    "print(\"finish step 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test image preprocessing functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_from_one_class_path = '00001/00001_00029.ppm'\n",
    "image_from_one_class_paths = os.path.join(root_dir, examples_from_one_class_path)\n",
    "\n",
    "def showImagesInGridImages(list_of_files):\n",
    "    fig = figure(figsize=(13, 13))\n",
    "    number_of_files = len(list_of_files)\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(number_of_files/7+1,2,i+1)\n",
    "#         image = imread(list_of_files[i])\n",
    "        imshow(list_of_files[i])\n",
    "\n",
    "images = []\n",
    "\n",
    "images.append(io.imread(image_from_one_class_paths, as_gray=True))\n",
    "img = io.imread(image_from_one_class_paths, as_gray=True)\n",
    "images.append(preprocess_img_without_rollaxis(img))\n",
    "\n",
    "showImagesInGridImages(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all training images into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    imgs = []\n",
    "    labels = []\n",
    "\n",
    "    all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "    np.random.shuffle(all_img_paths)\n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path, as_gray=True))\n",
    "            label = get_class(img_path)\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(imgs)%3000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "\n",
    "    with h5py.File('X.h5','w') as hf:\n",
    "        hf.create_dataset('imgs', data=X)\n",
    "        hf.create_dataset('labels', data=Y)\n",
    "\n",
    "    print(\"finish step 3\")\n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading X.h5. Processing all images...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(1, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum.\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))\n",
    "\n",
    "print(\"finish step 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 30\n",
    "\n",
    "model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True\n",
    "#           ,callbacks=[LearningRateScheduler(lr_schedule),\n",
    "#                     ModelCheckpoint('model.h5',save_best_only=True)]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('GT-final_test.csv',sep=';')\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "print(\"list lenght {})\".format(len(list(test['Filename']))))\n",
    "for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    img_path = os.path.join('GTSRB\\\\Final_Test\\\\Images\\\\',file_name)\n",
    "    X_test.append(preprocess_img(io.imread(img_path, as_gray=True)))\n",
    "    y_test.append(class_id)\n",
    "    if len(X_test)%1000 == 0: print(\"Processed {}/{}\".format(len(X_test), len(y_test)))\n",
    "    \n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_preciction = 0\n",
    "show_every_each = 10\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        bad_preciction += 1\n",
    "        if bad_preciction%show_every_each == 0:\n",
    "            print(\"No. {}: predicted: {} real: {}\".format(bad_preciction, y_pred[i], y_test[i]))\n",
    "            file_name = list(test['Filename'])[i]\n",
    "            img_path = os.path.join('GTSRB\\\\Final_Test\\\\Images\\\\',file_name)\n",
    "            imshow(preprocess_img_without_rollaxis(io.imread(img_path, as_gray=True)))\n",
    "            show()\n",
    "            img_path_for_sample_from_predicted_class = glob.glob(os.path.join(root_dir, '*00{}/00001_00010.ppm'.format(y_pred[i])))\n",
    "            imshow(preprocess_img_without_rollaxis(io.imread(img_path_for_sample_from_predicted_class[0], as_gray=True)))\n",
    "            show()\n",
    "            samples_to_show -= 1\n",
    "\n",
    "print(\"Wrong prediction for {} out of {} test samples\".format(bad_preciction, len(y_test)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
